---
title: "R Notebook"
output: html_notebook
---
# Contents
0. Global definitions
1. File Loading:
  1.1 Reference recordings: DONE
    - PitchTier
    - TextGrids: because we want to specify the Region of Interest (ROI),
                 the tone-carrying syllables at the end of the sentence
  1.2 Gesture files
  1.3 Vocal files: 

2. Preparing for comparison:
    - From TextGrids, identify the start and end time of ROI for each file
  2.1 Reference recordings
  2.2 Subject audio

3. Comparisons
  - Weighted correlation and RMSE, like before
  - But I think correlation is more meaningful in this case

4. Score Plots
  4.0 Consolidating scores
  4.1 Overall scores
  4.2 Scores by phrase

5. Frequency plots

---------------------------
# 0. Global definitions
```{r}
library(tidyverse)
library(rPraat)
library(gridExtra)
library(jsonlite)
library(timetk)
library(zoo)
library(MetricsWeighted)
library(wesanderson)
source("../utils/hertzToST.R")
options(dplyr.print_max = 1e9)
options(digits=8)

ref_freq <- 116.54

# Loading PitchTier, interpolate values every 0.01 seconds
load_pitchtier <- function(filename) {
  my_pt <- pt.read(filename)
  interpolated <- pt.interpolate(my_pt, seq(0, my_pt$tmax, by=0.01))
  interpolated$f <- hertz_to_semitones(interpolated$f, ref_freq)
  return(interpolated)
}

load_intensitytier <- function(filename) {
  my_it <- it.read(filename)
  interpolated <- it.interpolate(my_it, seq(0, my_it$tmax, by=0.01))
  return(interpolated)
}

load_textgrid <- function(filename) {
  return(tg.read(filename))
}

load_gest <- function(filename) {
  #print(filename)
  fromJSON(filename) %>% 
  # Make it into a tibble, convert t_init & t_end to from milliseconds to seconds
  as_tibble() %>% mutate(t_init=t_init/1000, t_end=t_end/1000)  
}

ref_ids <- c('3a', '3b', '5a', '5b', 'Aa', 'Ab', 'Ca', 'Cb')

# Get index of reference file
get_ref_index <- function(pt_filename) {
  phrase_id <- str_split(pt_filename, '-')[[1]][3]
  #print(paste("Phrase Id:", phrase_id))
  ref_index <- match(phrase_id, ref_ids)
  return(ref_index)
}

# Get the reference data based on phrase_id
get_ref_roi_data <- function(phrase_id) {
  index<-which(ref_ids==phrase_id)
  ref_data<-ref_pts_roi[[index]]
  num_points<-length(ref_data$f)
  my_data<-tibble(f=ref_data$f, t=ref_data$t, percent=seq(1, num_points)/num_points, condition="ref")
  return(my_data)
}

```

# 1. File Loading
## 1.1 Loading reference (demo) recordings
```{r}
# For REFERENCE recordings:
ref_path <- "../data/21_05-fallrise/reference/"

# - Load PitchTier and TextGrid filesnames
demo_pt_filenames <- dir(paste0(ref_path, "pt"))
demo_tg_filenames <- dir(paste0(ref_path, "tg"))
demo_it_filenames <- dir(paste0(ref_path, "it"))
# Use filenames to load PitchTier and TextGrid objects, stored in a list
ref_pts <- lapply(paste0(ref_path, "pt/",demo_pt_filenames), load_pitchtier)
ref_tgs <- lapply(paste0(ref_path, "tg/",demo_tg_filenames), load_textgrid)
ref_its <- lapply(paste0(ref_path, "it/",demo_it_filenames), load_intensitytier)

```

## 1.2 Loading gestures recorded from subjects
```{r}
# Load pitch contour (.gest) as JSON file
gest_path_learners <- "../data/21_05-fallrise/gest_learners/"
gest_path_natives <- "../data/21_05-fallrise/gest_natives/"

# Load filenames for gest & textgrids for LEARNERS
learners_gest_filenames <- dir(paste0(gest_path_learners, "gest"))
learners_tg_filenames <- dir(paste0(gest_path_learners, "tg"))
# Use filenames to load actual gest (as JSON) and textgrids
learners_gests <- lapply(paste0(gest_path_learners, "gest/", learners_gest_filenames), load_gest)
learners_gests_tgs <- lapply(paste0(gest_path_learners, "tg/", learners_tg_filenames), load_textgrid)

# Load filenames for gest & textgrids for NATIVES
natives_gest_filenames <- dir(paste0(gest_path_natives, "gest"))
natives_tg_filenames <- dir(paste0(gest_path_natives, "tg"))
# Use filenames to load actual gest (as JSON) and textgrids
natives_gests <- lapply(paste0(gest_path_natives, "gest/", natives_gest_filenames), load_gest)
natives_gests_tgs <- lapply(paste0(gest_path_natives, "tg/", natives_tg_filenames), load_textgrid)


```

## 1.3 Loading vocal recordingss
```{r}
# For Vocal Recordings
voice_learners_path <- "../data/21_05-fallrise/voice_learners/"
voice_natives_path <- "../data/21_05-fallrise/voice_natives/"
  
# Load filenames of pitchtiers & textgrids for LEARNERS free interpretation
learners_pt_filenames <- dir(paste0(voice_learners_path, "pt"))
learners_tg_filenames <- dir(paste0(voice_learners_path, "tg"))
# Use filenames to load actual pitchtiers and textgrids
learners_pts <- lapply(paste0(voice_learners_path, "pt/", learners_pt_filenames), load_pitchtier)
learners_tgs <- lapply(paste0(voice_learners_path, "tg/", learners_tg_filenames), load_textgrid)

# Load filenames for NATIVES, currently only 2 subjects free reading
natives_pt_filenames <- dir(paste0(voice_natives_path, "pt"))
natives_tg_filenames <- dir(paste0(voice_natives_path, "tg"))
# Use filenames to load actual pitchtiers and textgrids
natives_pts <- lapply(paste0(voice_natives_path, "pt/", natives_pt_filenames), load_pitchtier)
natives_tgs <- lapply(paste0(voice_natives_path, "tg/", natives_tg_filenames), load_textgrid)
```

# 2: Preparing for Comparison: 
## 2.1 Reference recordings
```{r}
# For each TextGrid in ref_tgs, get the time boundaries of ROI:

# For every PitchTier, only get the values in the ROI
ref_pts_roi <- seq(1, length(ref_tgs)) %>% lapply(function(index) {
  my_tg <- ref_tgs[[index]]
  roi_start <- my_tg$study$t1[2]
  roi_end <- my_tg$study$t1[3]
  return(pt.cut(ref_pts[[index]], tStart=roi_start, tEnd=roi_end))
})

# For every IntensityTier, only get the values in the ROI, normalize it
ref_its_roi <- seq(1, length(ref_tgs)) %>% lapply(function(index) {
  my_tg <- ref_tgs[[index]]
  roi_start <- my_tg$study$t1[2]
  roi_end <- my_tg$study$t1[3]
  my_it<-it.cut(ref_its[[index]], tStart=roi_start, tEnd=roi_end)
  # scale so that all the elements in the ROI add up to 1
  my_it$i<-my_it$i / sum(my_it$i)
  return(my_it)
})

```

## 2.2 Preparing vocal recordings
```{r}
# returns a function that prepares subject pitch tier file
# specify vectors for the filenames, pitchtiers (in semitones), and textgrids 
# returns the pitch tier cut to region of interest, scaled to same  number of points as
# its reference
get_subject_pt_prep_function <- function(filenames, pts, tgs) {  
  function(index) {  
    # Print index for debugging: 
    #print(paste("Current Index:", index))
    item <- filenames[[index]]
    # Find the index of that ref phrase
    ref_index <- get_ref_index(item)
    # Get the ref pitch tier (ROI)
    ref_pt <- ref_pts_roi[[ref_index]]
    # Get the ROI of subject's vocal recording
    subject_roi_start <- tgs[[index]]$study$t1[2]
    subject_roi_end <- tgs[[index]]$study$t1[3]
    pt_roi <- pt.cut(pts[[index]], tStart=subject_roi_start, tEnd=subject_roi_end)
  
    # Interpolate based on the number of points in the ROI of the reference pitchtier
    pt_roi_interp <- pt.interpolate(pt_roi, 
                     seq(subject_roi_start, subject_roi_end, length=length(ref_pt$f)))
  }
}

# Function to prepare the free reading files for LEARNERS
learners_prep <- get_subject_pt_prep_function(learners_pt_filenames, learners_pts, learners_tgs)
# The prepped PitchTiers for LEARNERS
learners_pts_roi <- seq(1, length(learners_pt_filenames)) %>% lapply(learners_prep)

# Prepare free reading files for NATIVES
natives_prep <- get_subject_pt_prep_function(natives_pt_filenames, natives_pts, natives_tgs)
# The prepped PitchTiers for NATIVES
natives_pts_roi <- seq(1, length(natives_pt_filenames)) %>% lapply(natives_prep)


```

## 2.3 Preparing gestures
```{r}

get_subject_gest_prep_function <- function(filenames, gests, tgs) {
  function(index) {
    file <- filenames[[index]]
    # Print index for debugging: 
    #print(paste("Current Index:", index))
    ref_index <- get_ref_index(file)
    # Get ref pitch tier (ROI)
    ref_pt <- ref_pts_roi[[ref_index]]
    # Get the ROI of subjects gesture recording
    subject_roi_start <- tgs[[index]]$study$t1[2]
    subject_roi_end <- tgs[[index]]$study$t1[3]
    ## Get the gesture, only keep the ROI
    gest <- gests[[index]] %>% 
      filter(t_init >= subject_roi_start & t_init <= subject_roi_end) %>%
      rename(t = t_init) %>% select(t, f, scrub) %>%
      # filter out rows with duplicates in t
      filter(duplicated(t)==FALSE)
    
    # Add end points at subject_roi_start & subject_roi_end 
    # if they don't already exist, duplicating first and last available f value
    if (! subject_roi_start %in% gest$t) {
      gest <- add_row(gest, t=subject_roi_start, f=gest$f[1], scrub=gest$scrub[1], .before=1)
    }
    if (! subject_roi_end %in% gest$t) {
      gest <- add_row(gest, t=subject_roi_end, f=tail(gest$f, 1), scrub=tail(gest$scrub, 1))
    }
    
    # Interpolation magic - 
    # Goal: scale the subject gest ROI to have the same number of points
    # as the reference ROI
    num_samples <- length(ref_pt$f) 
    # Create a tibble with all the points we are interested in, with NA values
    sample_points <- tibble(t =seq(subject_roi_start, subject_roi_end, 
                                 length.out=num_samples), f=NA, scrub=NA) 

    # Add all the sample points whose scrub value doesn't already exist in data
    gest2 <- bind_rows(gest, filter(sample_points, !(t %in% gest$t))) %>% arrange(t)
      
    # Transform into zoo object and fill in NAs with interpolated values
    z <- read.zoo(gest2) %>% na.approx %>%
      tk_tbl(preserve_index=TRUE, rename_index="t") %>%
      filter(t %in% sample_points$t) 
    return(z)
  }
}

# Function to prepare the gesture files for LEARNERS
learners_gests_prep <- get_subject_gest_prep_function(learners_gest_filenames, 
                                             learners_gests, learners_gests_tgs)
# Prepped gestures for LEANERS
learners_gests_roi <- seq(1, length(learners_gest_filenames)) %>% lapply(learners_gests_prep)

# Function to prepare the gesture files for NATIVES
natives_gests_prep <- get_subject_gest_prep_function(natives_gest_filenames, 
                                             natives_gests, natives_gests_tgs)
# Prepped gestures for NATIVES
natives_gests_roi <- seq(1, length(natives_gest_filenames)) %>% lapply(natives_gests_prep)
```

## 3. Comparison
```{r}
library("wCorr") # for the weighted correlation function

# Non-weighted Pearson's correleation
get_corr <- function(ref_pt, subject_pt, ref_it){
  weightedCorr(ref_pt, subject_pt, weights=ref_it, method="pearson")
}

get_rmse <- function(a, b, weights) {
  return(rmse(predicted=(a-mean(a)), actual=(b-mean(b)), w=weights))
}

# Returns a function that does comparison
# Specify vectors for the filenames, pitchtiers for subject and reference
# Specify type of comparison
get_comparison_function <- function(filenames, pts, ref_pts, ref_its, method) {
  function(index) {
    filename <- filenames[[index]]
    print(filename)
    # Find the index of that ref phrase
    ref_index <- get_ref_index(filename)
    # Get the ref pitch tier (roi) and intensity tier
    ref_pt <- ref_pts[[ref_index]]
    ref_it <- ref_its[[ref_index]]
    # Run the method    
    method(ref_pt$f, pts[[index]]$f, ref_it$i)
  }
} 


## CORRELATION SCORES
# Function that gets the weighted Pearson's Correlation scores for LEANERS Voice
get_corr_learners_voice <- get_comparison_function(learners_pt_filenames, learners_pts_roi, 
                                                 ref_pts_roi, ref_its_roi, get_corr) 
# The weighted Pearson's Correlation scores for LEARNERS
learners_voice_corr <- seq(1, length(learners_pt_filenames)) %>% sapply(get_corr_learners_voice)
# It's really bad, as expected :-)
mean(learners_voice_corr) # 0.205 for free, 0.586 for imitation    

# Function that gets the weighted Pearson's Correlation scores for NATIVES Voice
get_corr_natives_voice <- get_comparison_function(natives_pt_filenames, natives_pts_roi, 
                                                ref_pts_roi, ref_its_roi, get_corr) 
# The weighted Pearson's Correlation scores for NATIVES
natives_voice_corr <- seq(1, length(natives_pt_filenames)) %>% sapply(get_corr_natives_voice)
# It's not really that much better than the learners
mean(natives_voice_corr) # 0.380, 0.8306 for imitation

# Function that gets the weighted Pearson's Correlation scores for LEANERS Gestures
get_corr_learners_gest <- get_comparison_function(learners_gest_filenames, learners_gests_roi,
                                                  ref_pts_roi, ref_its_roi, get_corr)
learners_gest_corr <- seq(1, length(learners_gest_filenames)) %>% sapply(get_corr_learners_gest)
mean(learners_gest_corr) # 0.718 Yay!!

# Function that gets the weighted Pearson's Correlation scores for NATIVES Gestures
get_corr_natives_gest <- get_comparison_function(natives_gest_filenames, natives_gests_roi,
                                                  ref_pts_roi, ref_its_roi, get_corr)
natives_gest_corr <- seq(1, length(natives_gest_filenames)) %>% sapply(get_corr_natives_gest)
mean(natives_gest_corr) # 0.763 Yay!!

## RMSE SCORES
get_rmse_learners_voice <- get_comparison_function(learners_pt_filenames, learners_pts_roi, 
                                                   ref_pts_roi, ref_its_roi, get_rmse) 
learners_voice_rmse <- seq(1, length(learners_pt_filenames)) %>% sapply(get_rmse_learners_voice)
mean(learners_voice_rmse) #4.2

get_rmse_natives_voice <- get_comparison_function(natives_pt_filenames, natives_pts_roi, 
                                                  ref_pts_roi, ref_its_roi, get_rmse) 
# The weighted RMSE scores for NATIVES
natives_voice_rmse <- seq(1, length(natives_pt_filenames)) %>% sapply(get_rmse_natives_voice)

mean(natives_voice_rmse) # 3.34

# Function that gets the weighted RMSE scores for LEANERS Gestures
get_rmse_learners_gest <- get_comparison_function(learners_gest_filenames, learners_gests_roi,
                                                  ref_pts_roi, ref_its_roi, get_rmse)
learners_gest_rmse <- seq(1, length(learners_gest_filenames)) %>% sapply(get_rmse_learners_gest)
mean(learners_gest_rmse) # 3.05

# Function that gets the non-weighted RMSE scores for LEANERS Gestures
get_rmse_natives_gest <- get_comparison_function(natives_gest_filenames, natives_gests_roi,
                                                  ref_pts_roi, ref_its_roi, get_rmse)
natives_gest_rmse <- seq(1, length(natives_gest_filenames)) %>% sapply(get_rmse_natives_gest)
mean(natives_gest_rmse) # 3.03

```

## 4. Score Plots
### 4.0. Consolidating data
```{r}
learners_voice_info <- do.call("rbind", lapply(learners_pt_filenames, function(item) {
  name <- str_split(item, '.PitchTier')[[1]][1]
  info <- str_split(name, '-')[[1]]
  return(tibble(subject=info[1], type=info[2], pid=info[3], order=info[4], native=FALSE))
}))

natives_voice_info <- do.call("rbind", lapply(natives_pt_filenames, function(item) {
  name <- str_split(item, '.PitchTier')[[1]][1]
  info <- str_split(name, '-')[[1]]
  return(tibble(subject=info[1], type=info[2], pid=info[3], order=info[4], native=TRUE))
}))

learners_gest_info <- do.call("rbind", lapply(learners_gest_filenames, function(item) {
  name <- str_split(item, '.gest')[[1]][1]
  info <- str_split(name, '-')[[1]]
  return(tibble(subject=info[1], type=info[2], pid=info[3], order=info[4], native=FALSE))
}))

natives_gest_info <- do.call("rbind", lapply(natives_gest_filenames, function(item) {
  name <- str_split(item, '.gest')[[1]][1]
  info <- str_split(name, '-')[[1]]
  return(tibble(subject=info[1], type=info[2], pid=info[3], order=info[4], native=TRUE))
}))

# Adding scores to info tibble
learners_voice_scores <- learners_voice_info %>% add_column(corr=learners_voice_corr, rmse=learners_voice_rmse)
natives_voice_scores <- natives_voice_info %>% add_column(corr=natives_voice_corr, rmse=natives_voice_rmse)
learners_gest_scores <- learners_gest_info %>% add_column(corr=learners_gest_corr, rmse=learners_gest_rmse)
natives_gest_scores <- natives_gest_info %>% add_column(corr=natives_gest_corr, rmse=natives_gest_rmse)
all_scores<-rbind(learners_voice_scores, natives_voice_scores, learners_gest_scores, natives_gest_scores)

```

### 4.1 Overall scores
#### 4.1.a Correlation
```{r}
# Overall correlation scores
all_scores %>% 
  ggplot(aes(x=type, y=corr, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Correlation with Reference", 
            x="Condition", y="Correlation score")

```
#### 4.1.b. RMSE
```{r}
# Overall RMSE scores
all_scores %>% 
  ggplot(aes(x=type, y=rmse, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="RMSE with Reference", 
            x="Condition", y="RMSE score")

```

### 4.2 Scores by phrase
For free interpretation, natives sometimes had lower correlation scores for the "a" phrase, indicating more variation in pronunciation. For "b" phrases (fallrise), the non-natives consistently score worse.

For imitation, everyone does quite well across the board, but non-natives are not good with phrases 3b (Susan didn't get one credit) and Ab (Ken didn't feed the cat). 

#### 4.2.1.a Vocal scores: free reading vs. imitation (Correlation)
```{r}
# Correlation scores by phrase
corr_free <- all_scores %>% filter(type=="free") %>%
  ggplot(aes(x=pid, y=corr, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Vocal Correlation with Reference - Free", 
            x="Phrase", y="Correlation score") + 
  scale_fill_discrete(name = "Nativeness")

corr_imitation <- all_scores %>% filter(type=="imitation") %>%
  ggplot(aes(x=pid, y=corr, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Vocal Correlation with Reference - Imitation", 
            x="Phrase", y="Correlation score") +
  scale_fill_discrete(name = "Nativeness")

corr_chironomy <- all_scores %>% filter(type=="guide") %>%
  ggplot(aes(x=pid, y=corr, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Gestural Correlation with Reference - Chironomy", 
            x="Phrase", y="Correlation score") +
  scale_fill_discrete(name = "Nativeness")

grid.arrange(corr_free, corr_imitation, ncol=1)

```

#### 4.2.1.b. Vocal scores: free reading vs. imitation (RMSE)
```{r}

# RMSE scores by phrase
rmse_free <- all_scores %>% filter(type=="free") %>%
  ggplot(aes(x=pid, y=rmse, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Vocal RMSE with Reference - Free", 
            x="Phrase", y="RMSE score") + 
  scale_fill_discrete(name = "Nativeness")

rmse_imitation <- all_scores %>% filter(type=="imitation") %>%
  ggplot(aes(x=pid, y=rmse, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Vocal Correlation with Reference - Imitation", 
            x="Phrase", y="RMSE score") +
  scale_fill_discrete(name = "Nativeness")

rmse_chironomy <- all_scores %>% filter(type=="guide") %>%
  ggplot(aes(x=pid, y=rmse, fill=factor(native))) +
  geom_boxplot() + 
  labs(title="Vocal RMSE with Reference - chironomy", 
            x="Phrase", y="RMSE score") +
  scale_fill_discrete(name = "Nativeness")

grid.arrange(rmse_free, rmse_imitation, ncol=1)

```

#### 4.2.2.a Imitation scores: vocal vs. chironomy (Correlation)
```{r}
# Correlation scores by phrase
corr_learners <- all_scores %>% filter(type!="free" & native==FALSE) %>%
  ggplot(aes(x=pid, y=corr, fill=factor(type))) +
  geom_boxplot() + 
  labs(title="Correlation Scores for Non-natives", 
            x="Phrase", y="Correlation score") + 
  scale_fill_manual(name = "Type", labels=c("Gestural", "Vocal"), values=wes_palette("Moonrise3"))

corr_natives <- all_scores %>% filter(type!="free" & native==TRUE) %>%
  ggplot(aes(x=pid, y=corr, fill=factor(type))) +
  geom_boxplot() + 
  labs(title="Correlation Scores for Natives", 
            x="Phrase", y="Correlation score") + 
  scale_fill_manual(name = "Type", labels=c("Gestural", "Vocals"), values=wes_palette("Moonrise3"))

grid.arrange(corr_learners, corr_natives, ncol=1)

```

## 5. Frequency Plots
### 5.1. Preparing the data
```{r}
# Function factory to associate information with frequency curves
get_curve_info <- function(filenames, data, nativeness) {
  function(index) {
    # Get the filename, remove extension
    filename<-filenames[[index]]
    filename<-str_split(filename, '[.]')[[1]][1]
    # Get the parts of the filename
    filename_parts<-str_split(filename, "-")[[1]]
    # Get the gesture data
    gest_data<-data[[index]] 
    # Get the number of points, to calculate "percent" time
    num_points<-length(gest_data$f)
    my_percent<-seq(1, num_points)/num_points
    my_data<-tibble(f=gest_data$f, t=gest_data$t, percent=my_percent,
                         subject=filename_parts[1], condition=filename_parts[2], 
                         phrase=filename_parts[3], order=filename_parts[4], 
                         native=nativeness)
    return(my_data)
  }
}

# Function to get inforrmation for learners' gestures
get_learner_gest_info <- get_curve_info(learners_gest_filenames, learners_gests_roi, FALSE)
# All the learners gest data in a giant tibble
learners_gest_data<-do.call("rbind", lapply(seq(1, length(learners_gest_filenames)), get_learner_gest_info))

# Function to get information for natives' gestures
get_native_gest_info <- get_curve_info(natives_gest_filenames, natives_gests_roi, TRUE)
# All the native gest data in a giant tibble
natives_gest_data<-do.call("rbind", lapply(seq(1, length(natives_gest_filenames)), get_native_gest_info))

# Function to get information for learners' voice data
get_learner_voice_info <- get_curve_info(learners_pt_filenames, learners_pts_roi, FALSE)
# Learners voice data
learners_voice_data<-do.call("rbind", lapply(seq(1, length(learners_pt_filenames)), get_learner_voice_info))
learners_voice_imitation_data <- filter(learners_voice_data, condition=="imitation")
learners_voice_reading_data <- filter(learners_voice_data, condition=="free")

# Function to get information for natives voice info
get_native_voice_info <- get_curve_info(natives_pt_filenames, natives_pts_roi, TRUE)
natives_voice_data<-do.call("rbind", lapply(seq(1, length(natives_pt_filenames)), get_native_voice_info))
natives_voice_imitation_data <- filter(natives_voice_data, condition=="imitation")
natives_voice_reading_data <- filter(natives_voice_data, condition=="free")

```


```{r}
library(cowplot)

# Plots the refefence gesture with all the subject gestures
plot_curves_with_ref <- function(f0_data, phrase_id, subject_group_name, condition) {
  ref_data<-get_ref_roi_data(phrase_id)
  my_f0_data <- f0_data %>% filter(phrase==phrase_id)
  ggplot(ref_data, mapping=aes(x=percent, y=f, color="Ref")) + 
  geom_line(size=1.5) +
  geom_line(data=my_f0_data, mapping=aes(x=percent, y=f, color=subject)) +
  labs(title=paste0("Aligned Ref and Subject F0s, ", subject_group_name),
                 subtitle=paste0("Phrase: ", phrase_id, ",Condition: ", condition), 
                 y="Frequency (Semitones)", x="Percent time")
}

# Function that makes and saves plots for diff data sets
save_curves_ref_plots <- function(f0_data, subject_group, condition) {
  plot3a <- plot_curves_with_ref(f0_data, "3a", subject_group, condition)
  plot3b <- plot_curves_with_ref(f0_data, "3b", subject_group, condition)
  plot5a <- plot_curves_with_ref(f0_data, "5a", subject_group, condition)
  plot5b <- plot_curves_with_ref(f0_data, "5b", subject_group, condition)
  plotAa <- plot_curves_with_ref(f0_data, "Aa", subject_group, condition)
  plotAb <- plot_curves_with_ref(f0_data, "Ab", subject_group, condition)
  plotCa <- plot_curves_with_ref(f0_data, "Ca", subject_group, condition)
  plotCb <- plot_curves_with_ref(f0_data, "Cb", subject_group, condition)
  curves35 <- plot_grid(plot3a, plot3b, plot5a, plot5b, ncol=2)
  curvesAC <- plot_grid(plotAa, plotAb, plotCa, plotCb, ncol=2)
  filename35 <- paste("3ab5ab", subject_group, condition, sep="_")
  filenameAC <- paste("AabCab", subject_group, condition, sep="_")
  ggsave(paste0(filename35, ".png"), plot=curves35, device='png', path="../data/21_05-fallrise/_plots", width = 10, height = 8)
  ggsave(paste0(filenameAC, ".png"), plot=curvesAC, device='png', path="../data/21_05-fallrise/_plots", width = 10, height = 8)
}

save_curves_ref_plots(learners_gest_data, "Learners", "GesturalImitation")
save_curves_ref_plots(natives_gest_data, "Natives", "GesturalImitation")
save_curves_ref_plots(learners_voice_imitation_data, "Learners", "VocalImitation")
save_curves_ref_plots(natives_voice_imitation_data, "Natives", "VocalImitation")


```

